{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "**Deadline**:  17/09/2024, 17.00\n",
    "\n",
    "**Names and student numbers:**\n",
    "1. Albert Marques 15784169\n",
    "2. ...\n",
    "3. ...\n",
    "\n",
    "**Declaration of Originality**\n",
    "\n",
    "We whose names are given under 1., 2. and 3. above declare that:\n",
    "1. These solutions are solely our own work.\n",
    "2. We have not made (part of) these solutions available to any other student.\n",
    "\n",
    "## Instructions for completing and submitting the assignment\n",
    "Please pay attention to the following instructions:\n",
    "1. Please follow carefully the steps outlined in the assignment. If you cannot solve an exercise and this hinders continuing with subsequent exercises, try to find a way to work around it and give a clear explanation for the solution you have chosen.\n",
    "2. Submit your work in the form of a Jupyter notebook via Canvas, before the deadline. Your notebook should not give errors when executed with `Run All`.\n",
    "4. You are allowed to work on the assignment in groups of 2 or 3 students and to submit together. Before you submit, you and your team members have to register as an **Assignments group** on Canvas. Only a single member of each group has to submit the notebook. Please do **NOT** submit the same notebook multiple times!\n",
    "5. Please write your names also inside this markdown cell, under **Names and student numbers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: importing the relevant libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** import all the libraries you are using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: plagiarism detection\n",
    "\n",
    "In this part we want to compute a metric that measures the distance between two text documents. This allows us to find out whether two documents are similar. This is important for instance if you are Google, that tries to find how well a website matches to your search query. This distance will also allow us to detect duplicates (like Wikipedia mirrors) and cases of plagiarism (you are warned). \n",
    "\n",
    "The idea is to define distance in terms of shared words. We will think of a document D as a dictionary such that D[W] is the number of occurrences of word W. In other terms, we only keep track of how often each word occurs in the document. For example the documents \n",
    "\n",
    "    \"The dog ate the homework.\"\n",
    "and \n",
    "\n",
    "    \"The cat ate the homework.\"\n",
    "will be thought of as two dictionaries\n",
    "    \n",
    "    {\"the\": 2, \"dog\": 1, \"ate\": 1, \"homework\": 1}\n",
    "    {\"the\": 2, \"cat\": 1, \"ate\": 1, \"homework\": 1}\n",
    "\n",
    "Note that we make no distinction between upper and lower case words. \n",
    "\n",
    "To make the two documents comparable, we want to ensure that both dictionaries have the same keys, so\n",
    "\n",
    "    d1 = {\"the\": 2, \"dog\": 1, \"cat\": 0, \"ate\": 1, \"homework\": 1}\n",
    "    d2 = {\"the\": 2, \"dog\": 0, \"cat\": 1, \"ate\": 1, \"homework\": 1}\n",
    "\n",
    "An appropriate distance measure between two documents we will use is the angle between these documents. From linear algebra, we know that we can compute the angle between two vectors $\\vec{x}$ and $\\vec{y}$ with\n",
    "$$\\angle(\\vec{x}, \\vec{y}) = \\cos^{-1}\\left(\\frac{\\langle \\vec{x}, \\vec{y}\\rangle}{\\|\\vec{x}\\| \\|\\vec{y}\\|}\\right).$$\n",
    "If we extract only the word frequencies of the two documents as lists and consider them as vectors, we can compute their angle:\n",
    "\n",
    "    x = [2, 1, 0, 1, 1]\n",
    "    y = [2, 0, 1, 1, 1]\n",
    "    angle = arccos(6/7)\n",
    "    \n",
    "If the angle is zero, this means the two documents are identical (in terms of word counts), whereas an angle of 90 degrees means there are no common words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** in the cell below, create a function `compute_angle` that computes the angle between two texts. The input arguments are two strings of text and the function should return the angle (in radians). As a courtesy, we already defined the function and wrote a docstring for the function.\n",
    "\n",
    "Make sure your code has enough comments, so that a third reader can easily read and understand your code. Also make sure that interpunction (`.,!?:;`) is removed from the two texts, before computing the angle between them.\n",
    "\n",
    "In order to test your code, run the second cell below without making any changes to it.\n",
    "\n",
    "Hint: it is possible to write all your operations inside a single function `compute_angle`, but your code probably becomes better readable if you define auxiliary functions for sub-operations. Place these functions before the `compute_angle` function, so that you can call them in `compute_angle` when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_angle(text1, text2):#should not change text1, text2\n",
    "    \"\"\"\n",
    "    Return the angle (in radians) between two texts.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        text1 (str): First input text.\n",
    "        text2 (str): Second input text.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        angle (float): The angle in radians between the value vectors (the word counts).\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "        dictionary1 = {'the': 2, 'dog': 1, 'ate': 1, 'homework': 1}\n",
    "        dictionary2 = {'the': 2, 'ate': 1, 'homework': 1, 'cat': 1}\n",
    "        dictionary_angle(dictionary1, dictionary2)\n",
    "            0.541099525957146\n",
    "        \"\"\"\n",
    "    #Removes all the special characters from each text and converts all the letters to lowercase so we prevent word duplication.\n",
    "    text1_noch = re.sub(r'[^\\w\\s]',' ',text1.lower())\n",
    "    text2_noch = re.sub(r'[^\\w\\s]',' ',text2.lower())\n",
    "#Create a list out of the two texts. Each item of the list consists of a word. The spit() method help us to distinguish between words, denoting the space as the separator between words.\n",
    "    Text1 = text1_noch.split()\n",
    "    Text2 = text2_noch.split()\n",
    "#Creates an empty dictionary to store the different words as keys.\n",
    "    d1 = {}\n",
    "    d2 = {}\n",
    "#For every item in Text1, we check if there exists a key with each item of Text1 and Text2. If a key exists, we sum 1 as the word is repeated in the text. If a key didn't exist before, we create it and set a value of 1.\n",
    "    for i in Text1:\n",
    "        d1[i] = d1.get(i,0) + 1\n",
    "    for j in Text2:\n",
    "        d2[j] = d2.get(j,0) + 1\n",
    "#Both dictionaries may have different lengths, as the number of words in every text can differ. We aim to equalize the length of each dictionary in order to correctly make the product of both dictionaries.\n",
    "#We create a variable that contains the intersection of all the words in the two texts to check if the two dictionaries have keys for all the existing words.\n",
    "#If a key doesn't exist in one dictionary, we will create it and assign a value of 0. This is done in order to correctly dot product the two vectors.\n",
    "    total_keys=set(d1.keys()).union(set(d2.keys()))\n",
    "    for i in total_keys:\n",
    "        if i not in d2:\n",
    "            d2[i] = 0\n",
    "        elif i not in d1:\n",
    "            d1[i] = 0\n",
    "#Dot product of the two vectors.\n",
    "    numerator = sum(d1[k]*d2[k] for k in total_keys)\n",
    "#Norm calculations for both vectors and final calculation of the angle.\n",
    "    norm_1=np.sqrt(sum(d1[l]**2 for l in d1))\n",
    "    norm_2=np.sqrt(sum(d2[k]**2 for k in d2))\n",
    "    result=numerator/((norm_1)*(norm_2))\n",
    "    angle=np.arccos(result)\n",
    "\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541099525957146\n",
      "0.5889990007447885\n"
     ]
    }
   ],
   "source": [
    "#### DO NOT CHANGE THE CODE IN THIS CELL ####\n",
    "text1 = \"The dog ate the homework.\"\n",
    "text2 = \"The cat ate the homework.\"\n",
    "\n",
    "Obama = \"And Barack and I were raised with so many of the same values: \\\n",
    "         that you work hard for what you want in life; that your word \\\n",
    "         is your bond and you do what you say you're going to do; that \\\n",
    "         you treat people with dignity and respect, even if you don't know \\\n",
    "         them, and even if you don't agree with them. And Barack and I set \\\n",
    "         out to build lives guided by these values, and to pass them on to \\\n",
    "         the next generation. Because we want our children and all children \\\n",
    "         in this nation to know that the only limit to the height of your \\\n",
    "         achievements is the reach of your dreams and your willingness to \\\n",
    "         work for them.\"\n",
    "\n",
    "Trump = \"From a young age, my parents impressed on me the values that you \\\n",
    "         work hard for what you want in life, that your word is your bond and \\\n",
    "         you do what you say and keep your promise, that you treat people \\\n",
    "         with respect. They taught and showed me values and morals in their \\\n",
    "         daily lives. That is a lesson that I continue to pass along to our \\\n",
    "         son. And we need to pass those lessons on to the many generations to \\\n",
    "         follow. Because we want our children in this nation to know that the \\\n",
    "         only limit to your achievements is the strength of your dreams and \\\n",
    "         your willingness to work for them.\"\n",
    "\n",
    "print(compute_angle(text1, text2))\n",
    "print(compute_angle(Trump, Obama))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: wrangling and analyzing Twitter sentiment data\n",
    "This part of the assignment is about wrangling and analyzing Twitter sentiment data for six airline companies:\n",
    "\n",
    "|**Name Airline**|**@username**|\n",
    "|:-------|:-------------|\n",
    "|American Airlines       |@AmericanAir           |\n",
    "|JetBlue Airways        |@JetBlue              |\n",
    "|Southwest Airlines       |@SouthwestAir           |\n",
    "|United Airlines        |@united              |\n",
    "|US Airways        |@USAirways              |\n",
    "|Virgin America       |@VirginAmerica             |\n",
    "\n",
    "The dataset `DSM_assignment1_twitter_data.csv` consists of more than 14.000 tweets sent on 9 consecutive days in February 2015, all addressing one (or more) of the aforementioned airlines via the @username syntax. The text of the tweets can be found in the `text` column of the dataset. Another relevant column is called `tweet_created`, giving the time and day at which the tweet was sent.\n",
    "\n",
    "Furthermore, a machine learning algorithm has analyzed the content of the tweets and categorized the sentiment as positive, neutral or negative. This data can be found in `DSM_assignment1_sentiment_data.csv`. The sentiment can be found in the `airline_sentiment` column. The machine learning algorithm also estimates the probability that it identified the correct sentiment, which is given in the `airline_sentiment:confidence` column.\n",
    "\n",
    "The column `_unit_id` can be found in both datasets and can be used as a key to match the tweets with the sentiment data.\n",
    "\n",
    "(Note: US Airways was integrated into American Airlines in October 2015. Since our dataset is from February 2015, we will consider them as separate airlines.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** import the datasets `DSM_assignment1_twitter_data.csv` and `DSM_assignment1_sentiment_data.csv` and turn them into two DataFrames, called respectively `df_twitter` and `df_sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** during the creation of both datasets some lines/rows were duplicated. Remove the duplicates from both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** the machine learning algorithm is not always able to extract a sentiment from the tweet. This is reflected in a missing `airline_sentiment` value in `df_sentiment`. Remove the lines with a missing airline sentiment from the DataFrame and call the new DataFrame `df_sentiment_notnull`. Report the number of discarded lines by printing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** use the column `_unit_id` to merge the DataFrames `df_twitter` and `df_sentiment_notnull`. Call the resulting DataFrame `df`. Make sure that `df` contains only the entries that have both Twitter and sentiment data.\n",
    "\n",
    "Report the total number of tweets in the merged dataset, as well as the number of removed tweets from the Twitter dataset and the number of removed tweets from the sentiment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** crucially, what is still missing in the data is a column with the airline company that is being addressed in the tweet. This is done using Twitter's @username syntax, which is called a *mention*. For example, if the text of a tweet contains the (sub)string `@AmericanAir`, we may assume the tweet is addressed to American Airlines. We have to extract this information from the text of the tweet. This can be done using regular expressions, for instance (see [this](https://regexone.com) website for basic instructions). However, we have to be careful, as some tweets contain multiple mentions.\n",
    "\n",
    "This exercise contains three parts, corresponding to the three cells below:\n",
    "* in the first cell, create a new column called `mentions` in the `df`. The values of this column must be **lists** containing **all** the @username occurences (string type) in the text of a tweet. You can use regular expressions for extracting the @username occurences.\n",
    "* the second cell is a markdown cell, where you have to give an answer in plain text. In this cell, please explain carefully your approach for extracting the mentions from the tweet and the choices you have made. In particular, explain how you managed to extract **all** @username occurrences.\n",
    "* in the third cell, print the total number of mentions you have extracted from all tweets together, as well as the average number of mentions per tweet. Furthermore, draw a random sample of 15 entries of the `mentions` column and print the sample (as a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER IN PLAIN TEXT: ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: visualizing the California housing market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** use the California housing dataset of `sklearn` to create a figure with the following properties:\n",
    "* the figure shows the locations (in terms of longitude and latitude) of the houses in the dataset.\n",
    "* the coloring of each house in the plot should be based on its associated median house value, which is a continuous scale.\n",
    "* the figure should also contain a colorbar, indicating the scale of the coloring scheme.\n",
    "* the figure, the horizontal axis, the vertical axis and the colorbar should be labeled appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: comparing different regression methods\n",
    "\n",
    "The aim of this part of the assignment is to compare three regression estimators: polynomial regression, K-nearest neighbor regression and kernel regression. In order to control the underlying regression function, and to make sure that it is nonlinear, we use simulated data. The target variable $y = f(x)$ is a nonlinear function of the 1-dimensional feature $x$. In the cell below, the simulated data is imported and plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"DSM_assignment1_regression_data.csv\")\n",
    "x = data[:,0]\n",
    "y = data[:,1]\n",
    "\n",
    "plt.scatter(x, y, s=2, c='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** use $10$-fold cross-validation to estimate the root-mean-square error (RMSE) of a K-nearest neighbor regression model with uniform weights and with varying number of nearest neighbors taken into account. In other words, use the cell below to make a plot of the CV-estimated RMSE (**including** errorbars signifying one standard deviation) as a function of $K$. Choose the range of $K$ such that the bias-variance tradeoff is clearly visible in the plot.\n",
    "\n",
    "Finally, use the second cell below (the markdown cell) to explain, in your own words, the optimal choice for the value of $K$ based on your analysis.\n",
    "\n",
    "You may use existing packages to perform the K-nearest neighbors regression (e.g. sklearn, statsmodels), but the code for cross-validation may not rely on existing packages. However, you may freely copy and use code from the computer classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER IN PLAIN TEXT: ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:** repeat the previous exercise, but now for kernel regression with a Gaussian kernel. Plot the RMSE as a function of the bandwidth, instead of the number of nearest neighbors taken into account. Again, use the second cell below (the markdown cell) to explain, in your own words, the optimal choice for the value of the bandwidth based on your analysis.\n",
    "\n",
    "You may use existing packages to perform the kernel regression (e.g. sklearn, statsmodels), but the code for cross-validation may not rely on existing packages. However, you may freely copy and use code from the computer classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER IN PLAIN TEXT: ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11:** repeat the analysis of the two previous exercises, but now for polynomial regression. Plot the RMSE as a function of the degree of the polynomial, instead of the number of nearest neighbors taken into account or the bandwidth. Again, use the second cell below (the markdown cell) to explain, in your own words, the optimal choice for the value of the degree of the polynomial based on your analysis.\n",
    "\n",
    "You may use existing packages to perform the polynomial regression (e.g. sklearn, statsmodels), but the code for cross-validation may not rely on existing packages. However, you may freely copy and use code from the computer classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER IN PLAIN TEXT: ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12:** create a single plot that includes the original data and the optimal predictions according to the three methods of regression applied in the previous three exercises. Use a legend to make clear which prediction is associated with which method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13:** the DataFrame `df` that is uploaded in the cell below contains 9 missing values. Use your analysis of the previous exercises to complete the DataFrame by filling in and/or computing the missing values.\n",
    "\n",
    "Finally, use the markdown cell at the bottom of the notebook to explain (in your own words) whether or not, based on your analysis, any of the models is preferable over the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"DSM_assignment1_dataframe_empty.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER IN PLAIN TEXT: ####\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
